{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenizer_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYP9WeeLbSnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import bert\n",
        "import itertools\n",
        "pd.options.display.max_colwidth = 1000"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9-o5AOSb7NI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "29735d93-5ef6-4f3d-ba82-218ee13a4dc3"
      },
      "source": [
        "# Load Training dataset\n",
        "# dataset download link https://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\n",
        "columns = ['sentiment','id','date','query','user','text']\n",
        "df = pd.read_csv('train.csv',header=None,names=columns,engine='python',encoding='latin1')\n",
        "df.head(3)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>query</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment  ...                                                                                                                 text\n",
              "0          0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
              "1          0  ...      is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\n",
              "2          0  ...                            @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLRA70qyf0H6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "a3bd22b0-9b60-4b7a-e0b8-092a3adbd9d5"
      },
      "source": [
        "df['text'].sample(3)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1016144    @DistinQue Thanks for the mention in your #followfriday \n",
              "576268                           Very, very tired  crappy weather..\n",
              "1358562               @heroz: huzzah! all yours, i'll set it aside \n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFU5iUdmflLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to clean tweet\n",
        "def clean_tweet(tweet):\n",
        "    # convert html content to raw text\n",
        "    tweet = BeautifulSoup(tweet, \"lxml\").get_text()\n",
        "\n",
        "    # remove @ mentions\n",
        "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
        "\n",
        "    # Removing the URL links\n",
        "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
        "\n",
        "    # remove extra spaces\n",
        "    tweet = \" \".join(tweet.split())\n",
        "\n",
        "    return tweet"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD0yUMNXg8h5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['clean_tweet'] = df['text'].apply(clean_tweet)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp05AJUYhHOy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "31b3609b-1715-4710-d37b-2f579071d640"
      },
      "source": [
        "df[['text','clean_tweet']].sample(3)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1483894</th>\n",
              "      <td>@Hattz_4_Lifee i wish but i only found it on yt ,, but it still awesomee im going to buy her album when it comes out in my town</td>\n",
              "      <td>_4_Lifee i wish but i only found it on yt ,, but it still awesomee im going to buy her album when it comes out in my town</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696961</th>\n",
              "      <td>i'd rather spend my saturday evening reading Blink by Malcolm Gladwell. This honestly sucks!</td>\n",
              "      <td>i'd rather spend my saturday evening reading Blink by Malcolm Gladwell. This honestly sucks!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256968</th>\n",
              "      <td>@LilianTheNerd  Buuuuu como crees</td>\n",
              "      <td>Buuuuu como crees</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                     text                                                                                                                clean_tweet\n",
              "1483894  @Hattz_4_Lifee i wish but i only found it on yt ,, but it still awesomee im going to buy her album when it comes out in my town   _4_Lifee i wish but i only found it on yt ,, but it still awesomee im going to buy her album when it comes out in my town\n",
              "696961                                      i'd rather spend my saturday evening reading Blink by Malcolm Gladwell. This honestly sucks!                                i'd rather spend my saturday evening reading Blink by Malcolm Gladwell. This honestly sucks!\n",
              "256968                                                                                                 @LilianTheNerd  Buuuuu como crees                                                                                                           Buuuuu como crees"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5S6oCCmi21t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1ca35402-81e1-4ab1-8494-b1308f06e338"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1600000, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tOF_SHPi5Dh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "7a51ff37-6386-4bf3-af6a-b1b539c8c4c4"
      },
      "source": [
        "# create binary target variable\n",
        "df['target'] = (df['sentiment'] == 4).astype(int)\n",
        "df['target'].value_counts(normalize=True)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.5\n",
              "0    0.5\n",
              "Name: target, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAUpwchmjLxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create tokenizer\n",
        "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "\n",
        "# donwload bert small model from tensroflow hub\n",
        "url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\"\n",
        "bert_layer = hub.KerasLayer(url,trainable=False)\n",
        "\n",
        "# get model assets\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjHYfOXZkJ77",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dd81745a-b96b-4f16-bb3e-b864aa504d68"
      },
      "source": [
        "# bert uses word piece tokenizer which can out of vocab word by breaking into small chunks\n",
        "tokenizer.tokenize(\"i love itttt coefee\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'love', 'it', '##tt', '##t', 'coe', '##fe', '##e']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOeWyIV_kd47",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aa238830-114b-45d1-9e23-da1bd15f4d6e"
      },
      "source": [
        "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"i love itttt coefee\"))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1045, 2293, 2009, 4779, 2102, 24873, 7959, 2063]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V0YqS57jrzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to tokenize sentence using bert tokenizer and return the integer id for each token\n",
        "def bert_tokenize(sent,tokenizer):\n",
        "    return np.array(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sent)))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuPbpm73j4jK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['tokenize'] = df['clean_tweet'].apply(bert_tokenize,tokenizer=tokenizer)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJLzQ0uzkx2u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "958b09c0-dd42-4506-d6fa-d266c268907a"
      },
      "source": [
        "df['tokenize'].sample(3)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1130704                                                                   [2204, 2305, 10474, 1010, 2265, 2589, 1011, 2261, 6385, 2125, 2077, 5958, 6385, 2265]\n",
              "1305693                                                                                                       [2000, 5470, 1024, 3398, 2632, 4140, 1997, 20929]\n",
              "51947      [2129, 2116, 2111, 2024, 2025, 2183, 2000, 15216, 29247, 1029, 2017, 2064, 2022, 2035, 14777, 1998, 24067, 2100, 2007, 2033, 1012, 1026, 1064, 1017]\n",
              "Name: tokenize, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A9QtryynAux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# computing len of each tokens\n",
        "df['length'] = df['tokenize'].apply(lambda x : len(x))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKzHBn9DnbVP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "136aa343-b9c0-430a-db09-f4408a5e16e4"
      },
      "source": [
        "df['length'].describe()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1.600000e+06\n",
              "mean     1.787814e+01\n",
              "std      9.902549e+00\n",
              "min      0.000000e+00\n",
              "25%      1.000000e+01\n",
              "50%      1.700000e+01\n",
              "75%      2.500000e+01\n",
              "max      2.280000e+02\n",
              "Name: length, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e1sQZWCnhHA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "3172b014-b8ef-4cbd-a634-f26914a60664"
      },
      "source": [
        "# sort df by the length so that while feeding into batches we have all obs in batch with same length\n",
        "# this will will ensure we are adding same padding in each batch to improve training time performance\n",
        "# shuffling the data set  as well \n",
        "df = df.sample(frac=1,random_state=42)\n",
        "df.sort_values(by='length',inplace=True)\n",
        "df.head(3)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>query</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_tweet</th>\n",
              "      <th>target</th>\n",
              "      <th>tokenize</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>556869</th>\n",
              "      <td>0</td>\n",
              "      <td>2204382319</td>\n",
              "      <td>Wed Jun 17 02:04:11 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>gcdevine</td>\n",
              "      <td>@judithkeane</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391703</th>\n",
              "      <td>0</td>\n",
              "      <td>2054974194</td>\n",
              "      <td>Sat Jun 06 08:27:16 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>soniasierra</td>\n",
              "      <td>@evieeelove</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458013</th>\n",
              "      <td>4</td>\n",
              "      <td>2063629791</td>\n",
              "      <td>Sun Jun 07 03:26:41 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>karmified</td>\n",
              "      <td>@vishaltom</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         sentiment          id  ... tokenize length\n",
              "556869           0  2204382319  ...       []      0\n",
              "391703           0  2054974194  ...       []      0\n",
              "1458013          4  2063629791  ...       []      0\n",
              "\n",
              "[3 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG8oWTFOocMc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6a6be63d-8c76-4de8-ef47-c7e85b94adc8"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1600000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMX52szqoecl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e6b440fa-3044-4dc7-ba07-48c72d6c34c7"
      },
      "source": [
        "# keeping tweets with 5+ words for training\n",
        "MIN_LEN = 5\n",
        "sub_df = df[df['length'] >= MIN_LEN]\n",
        "sub_df.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1507385, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7cU8r-gtO3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert input and output in list of tuple\n",
        "gen = list(zip(sub_df['tokenize'],sub_df['target']))"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T08qxwsSnVaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuuRb9Kio-Zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create dataset generator for training\n",
        "dataset = tf.data.Dataset.from_generator(lambda:gen,output_types=(tf.int32, tf.int32))"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlnCdm4mp6rk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "23272a7c-c020-441c-a683-a879bbbf7060"
      },
      "source": [
        "# example of data gen\n",
        "next(iter(dataset))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(5,), dtype=int32, numpy=array([2009, 2515, 4757, 4757, 2015], dtype=int32)>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgSOVn5_p-3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "# get padded batches using padded batch \n",
        "batch = dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3S6PNzRuNnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test size for splitting batches into train and test batch\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "# Total  number of batch\n",
        "N_BATCH = int(np.ceil(sub_df.shape[0]/BATCH_SIZE))\n",
        "\n",
        "# shuffle batches before dividing into train and test\n",
        "batch.shuffle(N_BATCH)\n",
        "\n",
        "# Test batch count\n",
        "N_TEST_BATCH = int(N_BATCH * TEST_SIZE)\n",
        "\n",
        "\n",
        "# train and test batches\n",
        "test = batch.take(N_TEST_BATCH)\n",
        "train = batch.skip(N_TEST_BATCH)\n"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjQsVT6YuyK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build Text Classifier model using 1D CBB\n",
        "\n",
        "class classifier(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,vocab_size,emb_dim=128, nb_filters=50, FFN_units=512,dropout_rate=0.1,training=False):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        # define embedding layer\n",
        "        self.embedding = layers.Embedding(vocab_size,emb_dim)\n",
        "        \n",
        "        # biagram 1D CNN Layer\n",
        "        self.bigram = layers.Conv1D(filters=nb_filters, kernel_size= 2, padding=\"valid\", activation=\"relu\")\n",
        "        \n",
        "        # triagram 1D CNN Layer\n",
        "        self.trigram = layers.Conv1D(filters=nb_filters,kernel_size=3, padding=\"valid\",activation=\"relu\")\n",
        "        \n",
        "        # fourgram 1D CNN Layer\n",
        "        self.fourgram = layers.Conv1D(filters=nb_filters,kernel_size=4, padding=\"valid\", activation=\"relu\")\n",
        "        \n",
        "        # global maxpooling layer\n",
        "        self.pool = layers.GlobalMaxPool1D()\n",
        "        \n",
        "        # final full connected dense layer\n",
        "        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\n",
        "        \n",
        "        # drop out layer\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "\n",
        "        # final output layer     \n",
        "        self.last_dense = layers.Dense(units=1,activation=\"sigmoid\")\n",
        "\n",
        "        return\n",
        "    \n",
        "    def call(self, inputs, training):\n",
        "        x = self.embedding(inputs)\n",
        "        x_1 = self.bigram(x) # batch_size, nb_filters, seq_len-1)\n",
        "        x_1 = self.pool(x_1) # (batch_size, nb_filters)\n",
        "        x_2 = self.trigram(x) # batch_size, nb_filters, seq_len-2)\n",
        "        x_2 = self.pool(x_2) # (batch_size, nb_filters)\n",
        "        x_3 = self.fourgram(x) # batch_size, nb_filters, seq_len-3)\n",
        "        x_3 = self.pool(x_3) # (batch_size, nb_filters)\n",
        "        \n",
        "        merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)\n",
        "        merged = self.dense_1(merged)\n",
        "\n",
        "        # Dropout layer, have different behaviors during training and inference. \n",
        "        # For such layers, it is standard practice to expose a training (boolean) argument in the call() method.\n",
        "        merged = self.dropout(merged, training)\n",
        "        \n",
        "        output = self.last_dense(merged)\n",
        "        \n",
        "        return output"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4elDN3Gu7VD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define hyperparameters\n",
        "VOCAB_SIZE = len(tokenizer.vocab)\n",
        "EMB_DIM = 128\n",
        "NB_FILTERS = 10\n",
        "FFN_UNITS = 64\n",
        "DROPOUT_RATE = 0.2\n",
        "NB_EPOCHS = 3"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbZWbFPZ5_zU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1d4813e7-2d23-4a6e-af34-beb37eb3fe8d"
      },
      "source": [
        "VOCAB_SIZE"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syqscBr16BK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create model\n",
        "model = classifier(vocab_size=VOCAB_SIZE,emb_dim=EMB_DIM,nb_filters=NB_FILTERS,FFN_units=FFN_UNITS,dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9x1XPYz6RRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile model\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2WWlqKB6aco",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "44c1b833-95d6-4e1e-cce6-ac3f00f10b74"
      },
      "source": [
        "# save checkpoints\n",
        "checkpoint_path = \"ckpt_token\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(model=model)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Latest checkpoint restored!!\")"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Latest checkpoint restored!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPFT9vra6oLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# callback to save checkpoint\n",
        "class save_checkpoint_callback(tf.keras.callbacks.Callback):\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        ckpt_manager.save()\n",
        "        print(\"Checkpoint saved at {}.\".format(checkpoint_path))"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2INag41U6_RV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "33febd39-9914-49d1-881b-5c4a0af06b23"
      },
      "source": [
        "# train the model\n",
        "model.fit(train, epochs=NB_EPOCHS,callbacks=[save_checkpoint_callback()])"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "  18843/Unknown - 1097s 58ms/step - loss: 0.3531 - accuracy: 0.8446Checkpoint saved at ckpt_token.\n",
            "18843/18843 [==============================] - 1097s 58ms/step - loss: 0.3531 - accuracy: 0.8446\n",
            "Epoch 2/3\n",
            "18843/18843 [==============================] - ETA: 0s - loss: 0.3226 - accuracy: 0.8604Checkpoint saved at ckpt_token.\n",
            "18843/18843 [==============================] - 1102s 58ms/step - loss: 0.3226 - accuracy: 0.8604\n",
            "Epoch 3/3\n",
            "18843/18843 [==============================] - ETA: 0s - loss: 0.2965 - accuracy: 0.8735Checkpoint saved at ckpt_token.\n",
            "18843/18843 [==============================] - 1093s 58ms/step - loss: 0.2965 - accuracy: 0.8735\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9b48b91dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFt6vEroeOZ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8fd4aeb4-5609-4c9f-c442-7f22f1983133"
      },
      "source": [
        "# evaluate on test dataset\n",
        "eval = model.evaluate(test)\n",
        "print(eval)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4710/4710 [==============================] - 72s 15ms/step - loss: 0.4324 - accuracy: 0.8219\n",
            "[0.43240100145339966, 0.821888267993927]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXIuUo4s6__6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict = model.predict(test)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMKHkcVT8DR3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "0c7f2ba7-91cb-442c-fc39-ac00ac7abbe9"
      },
      "source": [
        "predict"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.43792996],\n",
              "       [0.01830937],\n",
              "       [0.85869336],\n",
              "       ...,\n",
              "       [0.00756258],\n",
              "       [0.03378687],\n",
              "       [0.08181273]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhrikAY_8Uv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
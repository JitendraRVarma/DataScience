{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import os\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)] # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int) # Iris Setosa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron model\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = per_clf.predict([[2, 0.5]])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling & validation set creation\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Keras Model Sequential  -- stacking layers\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Keras Model Sequential  -- list of layers\n",
    "# model = keras.models.Sequential([keras.layers.Flatten(input_shape=[28, 28]),\n",
    "#                                  keras.layers.Dense(300, activation=\"relu\"),\n",
    "#                                  keras.layers.Dense(100, activation=\"relu\"),\n",
    "#                                  keras.layers.Dense(10, activation=\"softmax\")\n",
    "#                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first layer param\n",
    "784 * 300 + 300    # +300 bias term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## second layers param\n",
    "300 * 100 + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x1a5ddb36358>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1a5baea3400>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1a5ddb36cf8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1a5ddc79080>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model.get_layer('dense').name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02448617, -0.00877795, -0.02189048, ..., -0.02766046,\n",
       "         0.03859074, -0.06889391],\n",
       "       [ 0.00476504, -0.03105379, -0.0586676 , ...,  0.00602964,\n",
       "        -0.02763776, -0.04165364],\n",
       "       [-0.06189284, -0.06901957,  0.07102345, ..., -0.04238207,\n",
       "         0.07121518, -0.07331658],\n",
       "       ...,\n",
       "       [-0.03048757,  0.02155137, -0.05400612, ..., -0.00113463,\n",
       "         0.00228987,  0.05581069],\n",
       "       [ 0.07061854, -0.06960931,  0.07038955, ..., -0.00384101,\n",
       "         0.00034875,  0.02878492],\n",
       "       [-0.06022581,  0.01577859, -0.02585464, ..., -0.00527829,\n",
       "         0.00272203, -0.06793761]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"sgd\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7237 - accuracy: 0.7644 - val_loss: 0.5207 - val_accuracy: 0.8234\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4843 - accuracy: 0.8318 - val_loss: 0.4345 - val_accuracy: 0.8538\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4393 - accuracy: 0.8454 - val_loss: 0.5341 - val_accuracy: 0.7988\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4126 - accuracy: 0.8565 - val_loss: 0.3915 - val_accuracy: 0.8644\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3940 - accuracy: 0.8618 - val_loss: 0.3748 - val_accuracy: 0.8690\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3753 - accuracy: 0.8677 - val_loss: 0.3707 - val_accuracy: 0.8728\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3633 - accuracy: 0.8715 - val_loss: 0.3623 - val_accuracy: 0.8720\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3519 - accuracy: 0.8750 - val_loss: 0.3848 - val_accuracy: 0.8624\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3416 - accuracy: 0.8792 - val_loss: 0.3588 - val_accuracy: 0.8704\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3324 - accuracy: 0.8819 - val_loss: 0.3427 - val_accuracy: 0.8780\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3243 - accuracy: 0.8835 - val_loss: 0.3433 - val_accuracy: 0.8786\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3151 - accuracy: 0.8866 - val_loss: 0.3310 - val_accuracy: 0.8820\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3083 - accuracy: 0.8885 - val_loss: 0.3262 - val_accuracy: 0.8888\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3024 - accuracy: 0.8914 - val_loss: 0.3387 - val_accuracy: 0.8774\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2950 - accuracy: 0.8939 - val_loss: 0.3205 - val_accuracy: 0.8864\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2892 - accuracy: 0.8972 - val_loss: 0.3083 - val_accuracy: 0.8908\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2841 - accuracy: 0.8977 - val_loss: 0.3546 - val_accuracy: 0.8740\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2780 - accuracy: 0.9000 - val_loss: 0.3138 - val_accuracy: 0.8902\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2729 - accuracy: 0.9021 - val_loss: 0.3130 - val_accuracy: 0.8898\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2678 - accuracy: 0.9035 - val_loss: 0.3271 - val_accuracy: 0.8804\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2626 - accuracy: 0.9056 - val_loss: 0.3069 - val_accuracy: 0.8918\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2578 - accuracy: 0.9072 - val_loss: 0.2971 - val_accuracy: 0.8960\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2538 - accuracy: 0.9082 - val_loss: 0.2986 - val_accuracy: 0.8936\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2485 - accuracy: 0.9105 - val_loss: 0.3073 - val_accuracy: 0.8882\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2447 - accuracy: 0.9121 - val_loss: 0.2970 - val_accuracy: 0.8954\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2409 - accuracy: 0.9136 - val_loss: 0.3055 - val_accuracy: 0.8888\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2366 - accuracy: 0.9155 - val_loss: 0.3019 - val_accuracy: 0.8952\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2331 - accuracy: 0.9167 - val_loss: 0.2993 - val_accuracy: 0.8930\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2287 - accuracy: 0.9182 - val_loss: 0.3052 - val_accuracy: 0.8892\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2255 - accuracy: 0.9187 - val_loss: 0.3032 - val_accuracy: 0.8930\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(15, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 78.9946 - accuracy: 0.8294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[78.99458312988281, 0.8294000029563904]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_new),axis=1)\n",
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparaing data for regression\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 22043.9473 - val_loss: 8.5689\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 47.2472 - val_loss: 4.3033\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 47.0789 - val_loss: 5.6353\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 45.0282 - val_loss: 7.6293\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 48.6190 - val_loss: 32.6265\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 42.7955 - val_loss: 19.8680\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 45.0575 - val_loss: 27.4110\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 52.4177 - val_loss: 1.5153\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 42.8383 - val_loss: 8.0325\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 37.3185 - val_loss: 10.6413\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 39.9309 - val_loss: 1.2077\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 37.7884 - val_loss: 127.5336\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 36.9179 - val_loss: 338.9418\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 39.4342 - val_loss: 11.0009\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 39.3454 - val_loss: 1.3528\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 34.8085 - val_loss: 10.8313\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 36.3370 - val_loss: 3.6199\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 40.3407 - val_loss: 308.0929\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 39.4864 - val_loss: 142.3401\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 35.2751 - val_loss: 0.9094\n",
      "162/162 [==============================] - 0s 965us/step - loss: 0.8907\n"
     ]
    }
   ],
   "source": [
    "# ANN for regression\n",
    "model = keras.models.Sequential([keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "                                 keras.layers.Dense(1)])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer='rmsprop')\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8907460570335388\n",
      "[[1.0866421]\n",
      " [1.7713727]\n",
      " [1.8141049]]\n"
     ]
    }
   ],
   "source": [
    "print(mse_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wide and Deep Neural Network using functional API with one input\n",
    "model_in = keras.layers.Input(shape=X_train.shape[1:])\n",
    "\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(model_in)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "\n",
    "concat = keras.layers.Concatenate()([model_in, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "\n",
    "model = keras.models.Model(inputs=[model_in], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 147.0075 - val_loss: 2.9851\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 90.2154 - val_loss: 1.3150\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 81.9733 - val_loss: 0.8356\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 71.1933 - val_loss: 55.3695\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 80.1836 - val_loss: 25.4222\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 48.8046 - val_loss: 0.8021\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 49.3656 - val_loss: 8.4368\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 42.1042 - val_loss: 5.3831\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 41.9673 - val_loss: 0.7604\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 37.0259 - val_loss: 19.4093\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 35.1292 - val_loss: 0.7720\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 32.6211 - val_loss: 2.5112\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 23.6430 - val_loss: 170.7824\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 24.4206 - val_loss: 16.8217\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 22.8891 - val_loss: 1.0620\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 19.4242 - val_loss: 1.5618\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 18.0387 - val_loss: 1.1456\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 19.1172 - val_loss: 150.6541\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 21.2719 - val_loss: 32.9597\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 14.6211 - val_loss: 8.4987\n",
      "162/162 [==============================] - 0s 772us/step - loss: 8.1494\n",
      "8.149446487426758\n",
      "[[3.2451518]\n",
      " [4.14564  ]\n",
      " [4.6325126]]\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer='rmsprop')\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "\n",
    "print(mse_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wide and Deep Neural Network using functional API with two inputs\n",
    "\n",
    "input_A = keras.layers.Input(shape=[5])\n",
    "input_B = keras.layers.Input(shape=[6])\n",
    "\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])\n",
    "model.compile(loss=\"mse\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2535.0195 - val_loss: 8.2356\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 123.8016 - val_loss: 8.6486\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 109.1110 - val_loss: 2.8909\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 94.3956 - val_loss: 3.3478\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 91.5698 - val_loss: 45.9808\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 51.1935 - val_loss: 280.8838\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 44.9423 - val_loss: 1.8714\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 53.3369 - val_loss: 6.5302\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 36.9041 - val_loss: 12.1785\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 35.0788 - val_loss: 1.6128\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 35.2145 - val_loss: 66.6051\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 33.9837 - val_loss: 1.4236\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 27.8110 - val_loss: 77.1143\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 26.2669 - val_loss: 17.3744\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 25.2613 - val_loss: 1.0066\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 23.9055 - val_loss: 84.6887\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 17.8206 - val_loss: 1.1956\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 17.6126 - val_loss: 261.7566\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 22.6928 - val_loss: 59.8525\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 15.7753 - val_loss: 0.7559\n",
      "162/162 [==============================] - 0s 772us/step - loss: 0.7335\n",
      "0.7334797382354736\n",
      "[[1.3146174]\n",
      " [1.7403414]\n",
      " [2.3601744]]\n"
     ]
    }
   ],
   "source": [
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))\n",
    "\n",
    "print(mse_test)\n",
    "print(y_pred)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with two input and two output\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "\n",
    "# multiple output\n",
    "model = keras.models.Model(inputs=[input_A, input_B],outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and weight for each output \n",
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 456.4582 - main_output_loss: 484.7685 - aux_output_loss: 201.6651 - val_loss: 49.0452 - val_main_output_loss: 52.2290 - val_aux_output_loss: 20.3904\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 143.0918 - main_output_loss: 153.4250 - aux_output_loss: 50.0928 - val_loss: 7.8384 - val_main_output_loss: 7.1844 - val_aux_output_loss: 13.7246\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 126.5891 - main_output_loss: 135.5635 - aux_output_loss: 45.8188 - val_loss: 5.0849 - val_main_output_loss: 4.5745 - val_aux_output_loss: 9.6786\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 87.5134 - main_output_loss: 92.8687 - aux_output_loss: 39.3158 - val_loss: 3.1866 - val_main_output_loss: 2.7894 - val_aux_output_loss: 6.7607\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 83.5235 - main_output_loss: 86.6924 - aux_output_loss: 55.0038 - val_loss: 3.1713 - val_main_output_loss: 2.5561 - val_aux_output_loss: 8.7080\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 56.5233 - main_output_loss: 60.5138 - aux_output_loss: 20.6088 - val_loss: 9.5987 - val_main_output_loss: 9.6633 - val_aux_output_loss: 9.0175\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 46.7079 - main_output_loss: 49.1516 - aux_output_loss: 24.7143 - val_loss: 1.3667 - val_main_output_loss: 1.3002 - val_aux_output_loss: 1.9647\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 36.7723 - main_output_loss: 37.4828 - aux_output_loss: 30.3773 - val_loss: 278.6000 - val_main_output_loss: 301.9402 - val_aux_output_loss: 68.5376\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 30.4434 - main_output_loss: 31.1715 - aux_output_loss: 23.8907 - val_loss: 4.3207 - val_main_output_loss: 4.5545 - val_aux_output_loss: 2.2167\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 21.4346 - main_output_loss: 21.9619 - aux_output_loss: 16.6889 - val_loss: 2.2045 - val_main_output_loss: 2.1391 - val_aux_output_loss: 2.7932\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 18.0233 - main_output_loss: 18.5196 - aux_output_loss: 13.5560 - val_loss: 65.1413 - val_main_output_loss: 70.6698 - val_aux_output_loss: 15.3848\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 16.9692 - main_output_loss: 17.3889 - aux_output_loss: 13.1922 - val_loss: 1.4162 - val_main_output_loss: 1.2785 - val_aux_output_loss: 2.6551\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 11.7128 - main_output_loss: 11.7995 - aux_output_loss: 10.9328 - val_loss: 119.2353 - val_main_output_loss: 127.3507 - val_aux_output_loss: 46.1968\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 11.0753 - main_output_loss: 11.1842 - aux_output_loss: 10.0953 - val_loss: 5.7878 - val_main_output_loss: 5.6372 - val_aux_output_loss: 7.1431\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 10.0166 - main_output_loss: 10.3275 - aux_output_loss: 7.2185 - val_loss: 1.0795 - val_main_output_loss: 0.8317 - val_aux_output_loss: 3.3100\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 8.4675 - main_output_loss: 8.8449 - aux_output_loss: 5.0709 - val_loss: 42.1576 - val_main_output_loss: 45.1147 - val_aux_output_loss: 15.5429\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 8.4716 - main_output_loss: 8.8889 - aux_output_loss: 4.7154 - val_loss: 1.0834 - val_main_output_loss: 1.0172 - val_aux_output_loss: 1.6794\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 8.2642 - main_output_loss: 8.6816 - aux_output_loss: 4.5085 - val_loss: 114.3419 - val_main_output_loss: 126.4381 - val_aux_output_loss: 5.4766\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 11.2492 - main_output_loss: 12.0044 - aux_output_loss: 4.4520 - val_loss: 26.7180 - val_main_output_loss: 28.6203 - val_aux_output_loss: 9.5974\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 8.2439 - main_output_loss: 8.5979 - aux_output_loss: 5.0582 - val_loss: 0.7914 - val_main_output_loss: 0.7119 - val_aux_output_loss: 1.5072\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.7698 - main_output_loss: 0.6882 - aux_output_loss: 1.5039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7698028683662415, 0.6882373690605164, 1.5038928985595703)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
    "total_loss, main_loss, aux_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7698029220104218"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9*main_loss + 0.1 * aux_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001A5E92FD268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1.1734118],\n",
       "        [1.597095 ],\n",
       "        [2.1400104]], dtype=float32),)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])\n",
    "y_pred_main, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2522546],\n",
       "       [1.4913131],\n",
       "       [1.2300426]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model building using subclassing API\n",
    "class WideAndDeepModel(keras.models.Model):\n",
    "\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) # handles standard args (e.g., name)\n",
    "        \n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        \n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        \n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "       \n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        \n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        \n",
    "        return main_output, aux_output\n",
    "\n",
    "sub_class_model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 261.5790 - output_1_loss: 263.7236 - output_2_loss: 242.2760 - val_loss: 6.4824 - val_output_1_loss: 6.6376 - val_output_2_loss: 5.0853\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 165.2875 - output_1_loss: 182.4976 - output_2_loss: 10.3961 - val_loss: 272.5189 - val_output_1_loss: 301.8724 - val_output_2_loss: 8.3383\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 155.1221 - output_1_loss: 171.3842 - output_2_loss: 8.7643 - val_loss: 15.3073 - val_output_1_loss: 16.6669 - val_output_2_loss: 3.0710\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 130.9639 - output_1_loss: 144.6144 - output_2_loss: 8.1090 - val_loss: 6.2793 - val_output_1_loss: 6.4602 - val_output_2_loss: 4.6515\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 146.7577 - output_1_loss: 161.3253 - output_2_loss: 15.6495 - val_loss: 34.8653 - val_output_1_loss: 38.2551 - val_output_2_loss: 4.3568\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 107.8161 - output_1_loss: 119.0137 - output_2_loss: 7.0388 - val_loss: 259.0634 - val_output_1_loss: 286.7392 - val_output_2_loss: 9.9810\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 95.9621 - output_1_loss: 105.9384 - output_2_loss: 6.1757 - val_loss: 31.1531 - val_output_1_loss: 34.2004 - val_output_2_loss: 3.7275\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 85.7509 - output_1_loss: 94.4707 - output_2_loss: 7.2729 - val_loss: 566.8775 - val_output_1_loss: 626.2820 - val_output_2_loss: 32.2356\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 82.7103 - output_1_loss: 90.6159 - output_2_loss: 11.5593 - val_loss: 1.5339 - val_output_1_loss: 1.3575 - val_output_2_loss: 3.1219\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 72.8222 - output_1_loss: 79.9767 - output_2_loss: 8.4317 - val_loss: 4.5064 - val_output_1_loss: 4.7076 - val_output_2_loss: 2.6953\n",
      "162/162 [==============================] - 0s 965us/step - loss: 4.0877 - output_1_loss: 4.2917 - output_2_loss: 2.2520\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001A5EB370840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "sub_class_model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer='rmsprop')\n",
    "\n",
    "history = sub_class_model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10,\n",
    "                              validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))\n",
    "\n",
    "total_loss, main_loss, aux_loss = sub_class_model.evaluate((X_test_A, X_test_B), (y_test, y_test))\n",
    "\n",
    "y_pred_main, y_pred_aux = sub_class_model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 672.7534 - val_loss: 82.4977\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 381.5422 - val_loss: 1086.3650\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 328.2492 - val_loss: 13.7559\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 275.6665 - val_loss: 22.9317\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 270.0629 - val_loss: 19.3198\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 218.5030 - val_loss: 620.9624\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 182.2321 - val_loss: 3.1678\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 237.4891 - val_loss: 6.0228\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 175.4698 - val_loss: 1.8787\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 155.1455 - val_loss: 2.0824\n",
      "162/162 [==============================] - 0s 675us/step - loss: 2.0590\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "                                 keras.layers.Dense(30, activation=\"relu\"),\n",
    "                                 keras.layers.Dense(1)])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer='rmsprop')\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving & restoring model\n",
    "model.save(\"my_keras_model.h5\")\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "337/363 [==========================>...] - ETA: 0s - loss: 140.4432WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 142.4475\n",
      "Epoch 2/10\n",
      "321/363 [=========================>....] - ETA: 0s - loss: 136.2672WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 127.6945\n",
      "Epoch 3/10\n",
      "358/363 [============================>.] - ETA: 0s - loss: 117.6271WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 118.3889\n",
      "Epoch 4/10\n",
      "360/363 [============================>.] - ETA: 0s - loss: 106.7131WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 105.9028\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - ETA: 0s - loss: 99.4294WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 99.4294\n",
      "Epoch 6/10\n",
      "353/363 [============================>.] - ETA: 0s - loss: 72.9428WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 72.9203\n",
      "Epoch 7/10\n",
      "331/363 [==========================>...] - ETA: 0s - loss: 59.0476WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 58.1188\n",
      "Epoch 8/10\n",
      "360/363 [============================>.] - ETA: 0s - loss: 55.1287WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 54.7203\n",
      "Epoch 9/10\n",
      "356/363 [============================>.] - ETA: 0s - loss: 43.7605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 44.4880\n",
      "Epoch 10/10\n",
      "355/363 [============================>.] - ETA: 0s - loss: 37.1205WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 37.4061\n"
     ]
    }
   ],
   "source": [
    "# callbacks to save checkpoint\n",
    "# checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\",save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 43.0082 - val_loss: 1.5227\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 35.0147 - val_loss: 29.5000\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 34.7994 - val_loss: 1.7463\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 31.9502 - val_loss: 4.1358\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 43.8798 - val_loss: 10.3506\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 27.5931 - val_loss: 132.9028\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 24.6392 - val_loss: 13.4895\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 29.3407 - val_loss: 4.6200\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 21.4222 - val_loss: 1.0363\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 20.3197 - val_loss: 11.5390\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 19.1564 - val_loss: 17.0297\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 17.8938 - val_loss: 1.1363\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 15.9808 - val_loss: 174.1543\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 16.9455 - val_loss: 17.6112\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 15.0432 - val_loss: 16.8166\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 14.4338 - val_loss: 48.3257\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 14.2490 - val_loss: 0.8568\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 15.3219 - val_loss: 142.3888\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 17.7785 - val_loss: 48.7664\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 12.9965 - val_loss: 0.8074\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 15.5397 - val_loss: 39.4429\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 13.4506 - val_loss: 0.8316\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 10.7010 - val_loss: 90.0636\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 12.3270 - val_loss: 0.8165\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 10.1973 - val_loss: 1.0208\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 9.8455 - val_loss: 1.8928\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 9.8855 - val_loss: 0.8507\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 9.1096 - val_loss: 0.7998\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 8.8293 - val_loss: 20.8727\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 7.7320 - val_loss: 2.3208\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 7.7876 - val_loss: 0.7614\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 8.8805 - val_loss: 2.1498\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 6.9693 - val_loss: 1.6282\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 8.5574 - val_loss: 13.0376\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 6.7892 - val_loss: 0.7910\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 6.0077 - val_loss: 0.7700\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 5.4075 - val_loss: 13.9782\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 5.4763 - val_loss: 0.7846\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 6.3014 - val_loss: 0.8599\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 4.1195 - val_loss: 0.7840\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 4.1336 - val_loss: 0.8701\n"
     ]
    }
   ],
   "source": [
    "# early stopping\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,validation_data=(X_valid, y_valid),callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_01_16-11_28_43'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "                                 keras.layers.Dense(30, activation=\"relu\"),\n",
    "                                 keras.layers.Dense(1)])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  1/363 [..............................] - ETA: 0s - loss: 63714.3125WARNING:tensorflow:From c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/363 [..............................] - ETA: 1:33 - loss: 40874.0977WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.5158s). Check your callbacks.\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 382.9419 - val_loss: 53.3961\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 111.5775 - val_loss: 79.1232\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 90.7779 - val_loss: 2.3024\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 71.5392 - val_loss: 1.8784\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 90.3656 - val_loss: 24.7476\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 48.2158 - val_loss: 5.1613\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 37.7393 - val_loss: 28.2299\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 38.7293 - val_loss: 232.9263\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 31.6435 - val_loss: 73.6129\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 23.1872 - val_loss: 1.3924\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 19.7307 - val_loss: 1.0755\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 18.6429 - val_loss: 1.4450\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 14.6587 - val_loss: 57.2552\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 14.3809 - val_loss: 97.7436\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 12.7651 - val_loss: 1.0215\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 11.1323 - val_loss: 9.1569\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 9.3488 - val_loss: 1.0190\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 9.9891 - val_loss: 19.6679\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 9.7629 - val_loss: 19.0314\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 6.3452 - val_loss: 1.1664\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 4.9788 - val_loss: 5.7944\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.8900 - val_loss: 0.9856\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.4845 - val_loss: 8.4938\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.6512 - val_loss: 1.0808\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.0689 - val_loss: 0.8675\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.9528 - val_loss: 0.7689\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.5405 - val_loss: 0.9068\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.4130 - val_loss: 0.9943\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1930 - val_loss: 1.2183\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0605 - val_loss: 0.7225\n"
     ]
    }
   ],
   "source": [
    "# run tensorboard command :  tensorboard --logdir=./my_logs --port=6006\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,validation_data=(X_valid, y_valid),callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter tunning\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\", **options))\n",
    "    options = {}\n",
    "    model.add(keras.layers.Dense(1, **options))\n",
    "    optimizer = keras.optimizers.RMSprop()\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn warapper\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "\n",
    "# keras_reg.fit(X_train, y_train, epochs=100,validation_data=(X_valid, y_valid),\n",
    "#               callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "\n",
    "# mse_test = keras_reg.score(X_test, y_test)\n",
    "\n",
    "# y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # randmoized search\n",
    "\n",
    "# param_distribs = {\"n_hidden\": [0, 1, 2, 3],\"n_neurons\": np.arange(1, 100),\"learning_rate\": reciprocal(3e-4, 3e-2),}\n",
    "\n",
    "# rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "\n",
    "# rnd_search_cv.fit(X_train, y_train, epochs=100,validation_data=(X_valid, y_valid),\n",
    "#                   callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0006154014789262348, 'n_hidden': 2, 'n_neurons': 87}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6136356790860494"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
